
---
title: "Homework 1 for SDS, Fall 2022"
author: "Cem Åžirin & Sophia Balestrucci & Vahid Ghanbarizadeh"
date: "`r Sys.Date()`"
---

## Exercise 2: Mind your own biz. . .

### Setting up the landscape

We want to be sure that we have the necessary functions before we start answering the questions. We will apply the Perturbed Histogram (Dwork et al., 2006) to privatize the data. The process starts with dividing the data into $m$ bins, and follows by adding noise to each bin count. Below is the function `perturb`, that takes the data, the number of bins, and the variance parameter $\epsilon$ as inputs, and returns the PMF for the original and perturbed data.The function `laplace` is to generate Laplacian noise. Lastly, the function `ePDF` constructs pdf functions from the probability mass functions obtained from the perturbed histogram.

```{r Introducing Functions 1}
rlaplace <- function(n, mu = 0, b = 1) {
  r <- runif(n, 0, 1)
  r <- mu - b * sign(r - 0.5) * log(1 - 2 * abs(r - 0.5))
  return(r)
}

perturb <- function(x, epsilon, breaks) {

  h <- hist(x, breaks = breaks, plot = FALSE)
  counts <- h$counts
  p_hat <- counts / sum(counts) * length(counts)

  # add noise to each bin
  counts <- counts + rlaplace(length(counts), 0, 2 / epsilon)
  # count 0 or max
  counts[counts < 0] <- 0 
  q_hat <- counts / sum(counts) * length(counts)

  # return $p_hat and $q
  return(list(p_hat = p_hat, q_hat = q_hat))
}

ePDF <- function(x, pmf, breaks) {
  # An m by n matrix to compare x with break points
  breaks_matrix <- matrix(breaks, nrow = length(x), ncol = length(breaks), byrow = TRUE)

  # An n-dimensional vector to store which bin each x falls into
  bins <- rowSums(breaks_matrix < x)

  # Assign the probability of each bin to the corresponding x
  d <- pmf[bins]

  # if x is outside the range of breaks, then d = 0
  d[is.na(d)] <- 0 

  return(d)
}
```

To test the functions, let's generate a random sample from a uniform distribution with mean 0 and standard deviation 1, and apply the perturbed histogram to it. We will use 10 bins, and $\epsilon = 0.1$.

```{r Testing Functions 1}
set.seed(123)
test1 <- perturb(runif(1000), 0.1, 0:10 / 10)

# Two barplots side by side
par(mfrow = c(1, 2))
barplot(test1$p_hat, main = "Original", col = "lightblue")
barplot(test1$q_hat, main = "Perturbed", col = "coral")
```



### Exercise 2.1

To compare the two approximations we are instructed to use Mean Integrated Squared Error (MISE). The MISE is defined as

$$
\text{MISE}(\hat{p}, p) = \mathbb{E}\left[ \int_{0}^{1} (p(x) - \hat{p}(x))^2 \, \mathrm{d}x \right]
$$

where $\hat{p}(i)$ is the probability of the $i$th bin of the approximate histogram, and $p(i)$ is the probability of the $i$th bin of the original histogram. Below is the function `mise` that takes the original and approximated PDFs as inputs, and returns MISE. And, below that is the function `sim_mise` where given the number of simulations (`S`), epsilon (`eps`), number of bins (`m`), and the true distrubution `rdist, ddist`; simulates data generation, perturbization, and the calculation of MISE scores. In the end, it returns the average MISE score. 


```{r Introducing Functions 2}
mise <- function(original, approx, start, end) {
  integrand <- function(x) (original(x) - approx(x))^2
  return(integrate(integrand, start, end, subdivisions = 1000, stop.on.error = FALSE)$value)
}

sim_mise <- function(S, eps, m, n, rdist, ddist) {
  # S: number of simulations
  # eps: epsilon
  # m: number of bins
  # n: sample size
  # rdist: random distribution
  # ddist: true distribution
  breaks <- 0:m / m

  p_mises <- rep(NA, S)
  q_mises <- rep(NA, S)
  for (i in 1:S) {
    # generate data
    x <- rdist(n)
    # get densities
    res <- perturb(x, eps, breaks)
    # compute MISE
    p_mises[i] <- mise(ddist, function(x) ePDF(x, res$p_hat, breaks), 0, 1)
    q_mises[i] <- mise(ddist, function(x) ePDF(x, res$q_hat, breaks), 0, 1)
  }
  return(list(p_mises = mean(p_mises), q_mises = mean(q_mises)))
}
```


Now, it is time to simulate the entire shebang. We are using the given grids for the parameters.

```{r Simulating Perturbed Histogram for Beta Distribution}
set.seed(123)
S <- 200 # We will change this to 1000 later
n_grid <- c(100, 1000)
eps_grid <- c(0.1, 0.001)
m_grid <- 1:10 * 5

# create data frame to store results
scores <- data.frame(matrix(NA, nrow = length(n_grid) * length(eps_grid) * length(m_grid), ncol = 5))
colnames(scores) <- c("n", "eps", "m", "p_mise", "q_mise")

rdist <- function(n) rbeta(n, 10, 10)
ddist <- function(x) dbeta(x, 10, 10)

# loop over n_grid, eps_grid and m_grid
i <- 1
for (n in 1:length(n_grid)) {
  for (eps in 1:length(eps_grid)) {
    for (m in 1:length(m_grid)) {
      # compute MISE scores for p_hat and q
      res <- sim_mise(S, eps_grid[eps], m_grid[m], n_grid[n], rdist, ddist)
      scores[i, ] <- c(n_grid[n], eps_grid[eps], m_grid[m], res$p_mises, res$q_mises)
      i <- i + 1
    }
  }
}

```

We will plot the MISE scores for $\hat{p}$ and $\hat{q}$ to have a better idea of what happenned during the simulations. We will refer to these plots in the next section.
```{r Plotting MISE Scores for Beta Distribution}
library(ggplot2)
# TODO: plotting p_hat for diferent epsilons is stupid change that

# plot MISE scores for p_hat
ggplot(scores, aes(x = m, y = p_mise, color = paste(n, eps))) + 
  geom_line() + 
  scale_color_discrete(name = "n, eps") + 
  labs(x = "Number of bins", y = "MISE", title = "MISE scores for p_hat for Beta(10, 10)")

# plot MISE scores for q
ggplot(scores, aes(x = m, y = q_mise, color = paste(n, eps))) + 
  geom_line() + 
  scale_color_discrete(name = "n, eps") + 
  labs(x = "Number of bins", y = "MISE", title = "MISE scores for q_hat for Beta(10, 10)")

```

### Exercise 2.2: Mixed distrubution
Now we create a function to create a mixed Beta distribution. Next, we plot the histogram of a test case.


```{r Mixed Beta Distribution}
rmbeta <- function(n, alphas, betas, probs) {
  if (length(alphas) != length(betas) | length(alphas) != length(probs)) {
    stop("alphas, betas and probs must have the same length")
  }
  # compute the density of a mixed beta distribution
  z <- sample(1:length(alphas), n, replace = TRUE, prob = probs)
 return(rbeta(n, alphas[z], betas[z]))
}

dmbeta <- function(x, alphas, betas, probs) {
  if (length(alphas) != length(betas) | length(alphas) != length(probs)) {
    stop("alphas, betas and probs must have the same length")
  }
  # compute the density of a mixed beta distribution
  return(rowSums(t(t(sapply(1:length(alphas), function(i) dbeta(x, alphas[i], betas[i]))) * probs)))
}

# Parameters for the mixed beta distribution
alphas <- c(2, 8)
betas <- c(8, 2)
probs <- c(0.3, 0.7)


# generate data
x <- rmbeta(1000, alphas, betas, probs)
# plot histogram
hist(x, breaks = 20, freq = FALSE, main = "Mixed beta distribution", col = "lightblue", xlim = c(0, 1))
# add density
curve(dmbeta(x, alphas, betas, probs), add = TRUE, col = "red")
```

```{r Simulating Perturbed Histogram for Mixed Beta Distribution}
S <- 200 # number of simulations
n_grid <- c(100, 1000)
eps_grid <- c(0.1, 0.001)
m_grid <- 1:10 * 5

# create data frame to store results
scores <- data.frame(matrix(NA, nrow = length(n_grid) * length(eps_grid) * length(m_grid), ncol = 5))
colnames(scores) <- c("n", "eps", "m", "p_mise", "q_mise")

# Distrubution parameters
alphas <- c(2, 8)
betas <- c(8, 2)
probs <- c(0.5, 0.5)

rdist <- function(n) rmbeta(n, alphas, betas, probs)
ddist <- function(x) dmbeta(x, alphas, betas, probs)

# loop over n_grid, eps_grid and m_grid
i <- 1
for (n in 1:length(n_grid)) {
  for (eps in 1:length(eps_grid)) {
    for (m in 1:length(m_grid)) {
      # compute MISE scores for p_hat and q
      res <- sim_mise(S, eps_grid[eps], m_grid[m], n_grid[n], rdist, ddist)
      scores[i, ] <- c(n_grid[n], eps_grid[eps], m_grid[m], res$p_mises, res$q_mises)
      i <- i + 1
    }
  }
}
```

Let's plot the MISE scores for $\hat{p}$ and $\hat{q}$ for the mixed beta distribution the same way we did for the "non-mixed" beta distribution.

```{r Plotting MISE Scores for Mixed Beta Distribution}

# plot MISE scores for p_hat, x axis: m
ggplot(scores, aes(x = m, y = p_mise, color = paste(n, eps))) + 
  geom_line() + 
  scale_color_discrete(name = "n, eps") + 
  labs(x = "Number of bins", y = "MISE", title = "MISE scores for p_hat")

# plot MISE scores for q, x axis: m
ggplot(scores, aes(x = m, y = q_mise, color = paste(n, eps))) + 
  geom_line() + 
  scale_color_discrete(name = "n, eps") + 
  labs(x = "Number of bins", y = "MISE", title = "MISE scores for q_hat")

```

#### Comparing the MISE scores for the non-mixed and mixed beta distribution

First comes the observations. It is hard to say the MISE scores for $\hat{p}$ differ much for the non-mixed and mixed beta distribution, however that is not the case for $\hat{q}$. We can see that the MISE scores for $\hat{q}$ are much lower for the mixed beta distribution. So we came up with some possible explanations for this.
 - The mixed beta distribution has a more suitable shape for fitting a histogram.
   - Now if this were the case, we would expect the MISE scores for $\hat{p}$ to be lower for the mixed beta distribution as well. That is why this explanation is not very likely.
 - The mixed beta distribution has a more "forgiving" density function.
   - What does forgivin mean? We will have to plot the density functions of the two distributions to show what we mean by this.

```{r Plotting Overlapping Density Functions}
curve(dmbeta(x, alphas, betas, probs), col = "red", add = TRUE, lwd = 2)
curve(dbeta(x, 10, 10), col = "blue", add = TRUE, lwd = 2)
```

The non-mixed beta distribution has more very high and low values compared to the mixed beta distribution. So imagine the bins around 0 to 0.2 and 0.8 to 1 for the non-mixed. When we get very large positive perturbizations we are heaviliy penalized for this. However, for the mixed beta distribution even for bins arround 0.5 we are not heavily penalized for large positive perturbations. Same reasoning applies for the very high values arround 0.4 to 0.6 for the non-mixed beta distribution. When we get large negative perturbations that drives the counts to 0 for those bins, the MISE will heavily penalize this.

So we can conclude the more dispersed the density function is, the more forgiving it is in terms of the MISE scores for $\hat{q}$. Our choice of parameters for the mixed beta distribution resulted in a more dispersed density function thus having lower MISE scores for $\hat{q}$.

### Exercise 2.3: Thinking very hard...

We have decided to export the number of steps taken by Cem from his iPhone. We would like Proffessor Brutti to give Cem some advice on running and maybe recommend him a new pair of running shoes since Brutti is has a deep knowledge of running shoes and Cem is quite slow. However, it is very dangerous for Brutti to know the number of steps taken by Cem since he might then extrapolate where Cem is running and set a trap for him, because Cem is quite annoying during lectures. 

```{r}
library(readr)
daily_steps <- read_csv("../data/daily_steps.csv", 
                        col_types = cols(date = col_date(format = "%Y-%m-%d"),
                                         value = col_integer()))

x <- daily_steps$value
# Number of bins
m      <- 20
breaks <- (0:m / m) * (max(x) - min(x)) + min(x)

# Let's see the distrubution
hist(x, breaks=breaks, main="Cem's daily steps after his arrival in Rome",
     col = 'wheat1')
```

We will assume that Cem can take at most 27,000 steps in a day, and normalize our data between 0 and 1. Now we will perturb the data before Cem falls into a trap. We would like choose optimal tuning parameters. 

As we increase number of bins $m$ we gain information by knowing the sample distribution in more detail. However, we add more noise to the data, therefore we must optimize this trade-off. 

Wasserman and Zhou (2010) suggests to choose $n^{1/3}$ bins. In the previous section we can see that 5 bins attained the best score for $n=100$, and maybe speculate that 10 bins was also the best for $n=1000$. This makes their suggestion more believable. Since we have extracted Cem's data only after his arrival in Rome, that ammounts to 67 days. So we expect 4 bins to be the optimal number of bins. 

They also suggest that the increase in $k$, i.e., the size of the private dataset we are going to hand over to Brutti, does not affect the differential privacy. So we will numerically test the relationship between the MISE score and $k$.

Lastly, we find $\epsilon=0.4$ to be satisfactory for our privacy requirements. The real data will be at most $e^{0.4} \approx 1.5$ more likely than any of its neighbours. And, Rome is quite so Brutti has to cover a lot of ground to catch Cem. 

```{r}
eps <- 0.4
x <- daily_steps$value / 27000
m <- 4
breaks <- (0:m / m)

res <- perturb(x, eps, breaks)
res
# Two barplots side by side
par(mfrow = c(1, 2))
# The values of the bins
barplot(res$p_hat, col = 'wheat1', main = 'Values of p-hat', space=0)
barplot(res$q_hat, col = 'wheat2', main = 'Values of q-hat', space=0)

dq_hat <- function(x) ePDF(x, res$q_hat, breaks)

# To sample from the distrubution of q-hat, we will use
# twice uniform sampling method, which i don't remember the name of.
rq_hat <- function(n, pmf) {
  u1 <- runif(n) # which bin does it belong to?
  u2 <- runif(n) # The value that it will inside the bin
  m <- length(pmf)

  bmatrix <- matrix(cumsum(pmf) / m, 
                    nrow = n, ncol = m, byrow = TRUE)

  bins <- rowSums(u1 > bmatrix)
  bins / m + u2 / m
}

z <- rq_hat(1000, res$q_hat)

breaksZ <- (0:20 / 20)
# Let's see the distrubution
par(mfrow = c(1, 2))
hist(x, breaks=breaksZ, main="Cem's daily steps after his arrival in Rome",
     col = 'cornsilk')
hist(z, breaks=breaksZ, main="and his privatized steps",
     col = 'lightblue')

```

Now let's see how similar is summary statistics of the original data and the perturbed data, for different values of $k$.

```{r}
M <- 10
k_grid <- c(100, 250, 500, 1000, 2500, 5000, 10000, 25000, 50000, 100000)

meanX <- mean(x)
sdX <- sd(x)

mean_diff <- array(NA, length(k_grid), dimnames = list(k_grid))
sd_diff   <- array(NA, length(k_grid), dimnames = list(k_grid))

for (i in 1:length(k_grid)) {
  mean_diff[i] <- mean(replicate(M, (mean(rq_hat(k_grid[i], res$q_hat)) - meanX)^2))
  sd_diff[i]   <- mean(replicate(M, (sd(rq_hat(k_grid[i], res$q_hat)) - sdX)^2))
}

par(mfrow = c(1, 2))
plot(k_grid, mean_diff, type = "l", xlab = "k", ylab = "Mean difference", main = "MSE of difference in means")
plot(k_grid, sd_diff, type = "l", xlab = "k", ylab = "SD difference", main = "MSE of difference in SDs")

```

Our simulations show after that $k=1000$ the MSE for the mean does not improve, and after $k=500$ the MSE for the SD does not improve. So we do not see any advantage in increasing $k$ beyond 1000, therefore we will use $k=1000$.

### Excercise 2.4: Proving $\epsilon$-privacy

We will prove that the data release mechanism $\mathcal{Q}_n(\cdot \mid \mathcal{D}_n)$ using Perturbed Histogram satisfies $\epsilon$-differential privacy by simulating the algorithm with random samples and its random neighbours.

Let's revisit the definition of differential privacy:

$$
\sup_{z \in \mathcal{Z}} \frac{\mathcal{Q}_n(z \mid \mathcal{D}_n)}{\mathcal{Q}_n(z \mid \mathcal{D}_n^{\prime})} \leq e^{\epsilon}
$$

In our simulation, we will derrive the PDFs for the data releasing mechanism given both the original and neighbouring dataset. Then, find $z$ which maximizes the ratio of the PDFs. We will repeat this process for $M$ random samples and their neighbours.

```{r Bonus, warning=FALSE}

perturb_V2 <- function(x, xprime, epsilon, breaks) {
  # x: the original data
  # xprime: the neighbouring data
  # epsilon: the privacy parameter
  # breaks: break points for the bins

  # Count the number of observations in each bin
  counts      <- hist(x,      breaks = breaks, plot = FALSE)$counts
  countsprime <- hist(xprime, breaks = breaks, plot = FALSE)$counts

  # We are adding the same noise both to the original 
  # and the neighbouring dataset so we save it. 
  noise <- rlaplace(length(counts), 0, 2 / epsilon)

  counts      <- counts      + noise
  countsprime <- countsprime + noise

  # appling max(0, count)
  counts[counts < 0] <- 0 
  countsprime[countsprime < 0] <- 0

  q_hat      <- counts / sum(counts) * length(counts)
  q_hatprime <- countsprime / sum(countsprime) * length(countsprime)

  # return $p_hat and $q
  return(list(q_hat = q_hat, q_hatprime = q_hatprime))
}

# Let's see how the perturb_V2 works
eps <- 1.1
M   <- 1000

# df to store the maximum ratio
odds_df <- data.frame(n = rep(NA, M), maximum = rep(NA, M))

for (j in 1:M) {
  # Randomize numer of observations
  n <- sample(1:1000, 1)

  # Generate random data and change the first observation randomly
  X      <- rbeta(n, 10, 10)
  Xprime <- X
  Xprime[1] <- rbeta(1, 10, 1)

  # optimal number of bins and corresponding breaks
  m <- round(n^(1/3))
  breaks <- (0:m / m)

  # perturb the data
  res <- perturb_V2(X, Xprime, eps, breaks)
  odds <- res$q_hat / res$q_hatprime
  odds_df[j, ] <- c(n, log(max(odds[!is.nan(odds)])))
}

ggplot(odds_df, aes(x = n, y = maximum)) + 
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = log(2), linetype = 2) + 
  ggtitle("Value of epsilon that satisfies the maximum threshold")

```

In the plot above, our evidence is that the epsilon that satisfies the maximum threshold is (almost) always less the epsilon we have chosen. So we can say that the pertubrized histogram (almost) satisfies $\epsilon$-differential privacy.

So, there are actually cases where the maximum ratio is more than $e^{\epsilon}$. We are not sure how to interpret this. We know that it is mathematically possible. Say, that the neighbouring data count of bin $j$ is $n_j' = n_j-1$, and we can say the odds are dependent on $\lim_ {\nu_j \to -(n_j-1)^+} \frac{\max(0, n_j + \nu_j)}{\max(0, n_j-1 + \nu_j)} = \infty$. This can indeed occur in sparse datasets. 

For example if we take the amount wealth accumulated by our classmates and afterwards add Bill Gates to the dataset we can have a similar situation. The odds of generating a billionare in the dataset will be affected by the way we have just described. We have not read the entire literature on this topic, so we are not quite sure how to tackle this problem. So it is either we misundertood the definition of differential privacy, and how to calculate the odds, or we are missing something in the literature (like sparcity constraints?). Or pertubrized histograms do not satisfy differential privacy.

We would appreciate any feedback on this. Thanks for reading!